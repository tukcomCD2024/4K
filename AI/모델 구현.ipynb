{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, LSTM, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# 사전 데이터 불러오기\n",
    "word_to_id = pd.read_csv(\"word_to_id.csv\", encoding='utf-8')\n",
    "id_to_word = pd.read_csv(\"id_to_word.csv\", encoding='utf-8')\n",
    "\n",
    "# 정수화된 문장 데이터 불러오기\n",
    "standard_data = pd.read_csv(\"standard_padding_data.csv\", encoding='utf-8')\n",
    "dialect_data = pd.read_csv(\"dialect_padding_data.csv\", encoding='utf-8')\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 저장한 Word2Vec 모델 불러오기\n",
    "dialect_word2vec = Word2Vec.load(\"dialect_word2vec.bin\")\n",
    "standard_word2vec = Word2Vec.load(\"standard_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x24f4283ef08>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x24f427d2648>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108341\n",
      "108341\n",
      "331083\n",
      "331083\n"
     ]
    }
   ],
   "source": [
    "print(len(word_to_id))\n",
    "print(len(id_to_word))\n",
    "print(len(standard_data))\n",
    "print(len(dialect_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331083, 40)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331083, 40)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X_train_dialect, X_test_dialect, y_train_standard, y_test_standard = train_test_split(dialect_data ,standard_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264866, 40)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dialect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66217, 40)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dialect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264866, 40)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66217, 40)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 40)]              0         \n",
      "                                                                 \n",
      " embedding_47 (Embedding)    (None, 40, 100)           10084400  \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 38, 64)            19264     \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 19, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 19, 64)            0         \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 19, 64)            33024     \n",
      "                                                                 \n",
      " time_distributed_29 (TimeDi  (None, 19, 108341)       7042165   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,178,853\n",
      "Trainable params: 17,178,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "dialect_embedding_matrix = dialect_word2vec.wv.vectors\n",
    "standard_embedding_matrix = standard_word2vec.wv.vectors\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "max_length = 40\n",
    "input_layer = Input(shape=(max_length,), dtype='float32')\n",
    "\n",
    "# 임베딩 레이어\n",
    "embedding_layer = Embedding(input_dim=dialect_embedding_matrix.shape[0], output_dim=dialect_embedding_matrix.shape[1], weights=[dialect_embedding_matrix], input_length=max_length, trainable=True)(input_layer)\n",
    "\n",
    "# CNN 레이어\n",
    "conv_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding_layer)\n",
    "pooling_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
    "\n",
    "# 과적합 방지를 위한 드롭아웃 레이어\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "\n",
    "# LSTM 레이어\n",
    "lstm_layer = LSTM(units=64, return_sequences=True)(dropout_layer)\n",
    "\n",
    "# 완전 연결 레이어\n",
    "output_layer = TimeDistributed(Dense(units=vocab_size, activation='softmax'))(lstm_layer)\n",
    "\n",
    "# 모델 생성wd\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 모델 컴파일 \n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# type(dialect_data)\n",
    "\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "y_train_standard_array = y_train_standard.values\n",
    "y_train_standard_padded = pad_sequences(y_train_standard_array, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 970, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 40 and 19 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Cast_25, Cast_26)' with input shapes: [?,40], [?,19].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13228\\808549088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_dialect\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train_standard_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_dialect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_dialect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy: {accuracy * 100:.2f}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\edcrf\\anaconda3\\envs\\new_thing\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 970, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 40 and 19 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Cast_25, Cast_26)' with input shapes: [?,40], [?,19].\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "hist = model.fit(X_train_dialect , y_train_standard_padded, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "loss, accuracy = model.evaluate(X_test_dialect, y_test_dialect)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input, Embedding, Dense, TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 같은 딥러닝 프레임워크는 주로 numpy 배열을 입력으로 받음\n",
    "# 때문에 values 속성 사용해 Pandas 데이터프레임을 Numpy 배열로 변환\n",
    "input_sequences = dialect_data.values\n",
    "output_sequences = standard_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "# 임베딩 레이어: 단어를 밀집된 벡터로 변환\n",
    "# 첫번째 LSTM 레이어: 데이터의 패턴을 학습\n",
    "# RepactVector 레이어: 출력 시퀀스의 길이만큼 입력을 반복\n",
    "# 두번째 LSTM 레이어: 첫번째 LSTM 레이어와 마찬가지로 패턴을 학습\n",
    "# Dense 레이어: 단어 사전의 크기에 따라 출력 크기 설정하고, softmax 함수 사용해 확률 분포 출력\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_to_id)+ 1, 256, input_length=input_sequences.shape[1]),\n",
    "    tf.keras.layers.LSTM(256),\n",
    "    tf.keras.layers.RepeatVector(output_sequences.shape[1]),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.Dense(len(word_to_id) + 1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 compile\n",
    "# 모델이 훈련 가능한 상태가 되도록 하는 것\n",
    "# optimizer는 학습률을 조절해 최적화하는 방법이며 adam은 RMSProp과 Momentum 방식을 결합한 방식\n",
    "# Loss function은 손실 값을 측정하는 방법이며 여기서는 훈련 데이터의 라벨 값이 정수이므로 sparse_categorical_crossentropy 사용\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(input_sequences))\n",
    "print(type(output_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367954\n",
      "367954\n",
      "128707\n"
     ]
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "print(len(output_sequences))\n",
    "print(len(word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint 콜백 정의\n",
    "checkpoint_callback = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 시 fit() 메서드의 callbacks 인자에 콜백 전달\n",
    "history = model.fit(input_sequences, np.expand_dims(output_sequences, -1), epochs=100, batch_size=64, validation_split=0.2, callbacks=[checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_thing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
